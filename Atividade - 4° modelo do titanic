import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
import seaborn as sns

#conhecer um banco de dados ,e com pedições prever um novo conjuto de dados 
#train e test - generalização , usar dados novos , não dados de test , para testar a eficacia ,e  sim os dados do train 
# pra tal vou  modelar usando o train 
#gender submission me da:
    
####### inicio do codigo #########
train = pd.read_csv('../input/titanic/train.csv')
test = pd.read_csv('../input/titanic/test.csv')


### VIZUALIZAÇÃO DO BANCO DE DADOS ###

## leganda do banco de dados ##
#PassengerId - indentificador de cada passageiro 
#survived - o que eu preciso prever , se sobreviveu ou não no naufragio 
#Pclass - qual classe ele estava (1° , 2° , 3° )
#name - é o nome né 
#sex - seguindo a logica de mulheres e crianças priemiro 
#idade - idade do individo 
#SibSp - indicador se a pessoa estava viajando com alguém , acompanhante ou coisa do tipo 
#Parch - se a pessoa estava aconapnhanda de filhos , ou era filha de alguém que estvaa lá 
#Ticket - o numero d apassagem 
# fare - é o preço da passsagem da pessoa 
# cabin - o numero da cabine da pessoa 
#Embarked - em qual porto ela embracou no navio( S,C , e mais um )



##### Importando o programa da  QUESTÃO 8
## item A, B, C ##
train = pd.read_csv('../input/titanic/train.csv')
test = pd.read_csv('../input/titanic/test.csv')

train = pd.read_csv('../input/titanic/train.csv')
test = pd.read_csv('../input/titanic/test.csv')



train_clean = train
test_clean = test
print()
train.describe( )
print()
print()
test.describe()
train.info()
print()
print()
test.info()
print()
print()
print ('Os valores vazios')
print()
print('No dataframe de test')
print(test_clean.isnull().sum())
print()
print()
print('No dataframe de treino')
print(train_clean.isnull().sum())


# a mediana das idades faltando 
media_idade = test_clean['Age'].median().round(4)
test_clean['Age'] = test_clean['Age'].fillna(media_idade).round(4)

media_idade_treino = train_clean['Age'].median().round(4)
train_clean['Age'] = train_clean['Age'].fillna(media_idade_treino).round(4)

# a mediana dos valores de fare faltando 
media_fare = test_clean['Fare'].median().round(4)
test_clean['Fare'] = test_clean['Fare'].fillna(media_fare).round(4)

media_fare_treino = np.median(train_clean['Fare']).round(4)
train_clean['Fare'] = train_clean['Fare'].fillna(media_fare_treino ).round(4)

#a moda dos valores de embarked 
moda = test['Embarked'].mode()
test_clean['Embarked'] = test_clean['Embarked'].fillna(moda)
moda_treino = train['Embarked'].mode()
train_clean['Embarked'] = train_clean['Embarked'].fillna(moda_treino)


test1= test_clean.loc[:,['Age', 'Fare', 'Sex', 'Embarked', 'Pclass', 'SibSp', 'Parch']]
train1 = train_clean.loc[:,['Age', 'Fare', 'Sex', 'Embarked', 'Pclass', 'Survived', 'SibSp', 'Parch']]
train1=train1.dropna()
test1=test1.dropna()


### Item D ### 

# Usando de Auxilio uma função já existente. 
from sklearn.preprocessing import OneHotEncoder


def dummyEncode(pm):
        columnsToEncode = list(pm.select_dtypes(include=['object']))
        train1 = pm
        test1 = test
        s = (train1.dtypes == 'object')
        oc = list(s[s].index)
        le = OneHotEncoder(handle_unknown='ignore', sparse=False)
        for feature in oc:
            try:
                one = pd.DataFrame(le.fit_transform(train1[oc]))
                one.index=pm.index
            except:
                print('Error encoding '+feature)
            one.columns = le.get_feature_names(oc)
            v = pd.DataFrame(le.transform(pm[oc]))
            c = pd.concat([pm,one], axis=1)
            return c
        
        
train_encordado = dummyEncode(train)
teste_encordado = dummyEncode(test)
display(train_encordado)


# converter colunas categoricas em colunas numericas , usando a função do item 8.1 - d
train_encordado = pd.get_dummies(train1, columns=['Sex', 'Embarked'])

# Variavel de entrada pra treinar o modelo 
#somente variaveis numericas
features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male', 
            'Embarked_C', 'Embarked_Q', 'Embarked_S']


target = 'Survived'

 
x = train_encordado[features].fillna(-1)
#o que queremos prever 
y = train_encordado[target]





# a VALIDAÇÃO CRIZADA DE DADOS 

from sklearn.model_selection import KFold
from sklearn.model_selection import RepeatedKFold
from sklearn.ensemble import RandomForestClassifier #arvore de decisçao
from sklearn.linear_model import LogisticRegression
resultados2 = []
resultados3 = []
    #aqui os resultados depois de toda o treino com a validação cruzada : 
kf = RepeatedKFold(n_splits = 2 , n_repeats = 5, random_state=10)
    #função que retorna pra gente condições de "se" , retornar indices , de cada divisão para que se possa testar 


#### aqui o teste usando o Random Forest 
for linhas_treino , linhas_valid in kf.split(x) :
    print("Treino",linhas_treino.shape[0])
    print ("Valid", linhas_valid.shape[0])
    print()
    x_treino , x_valid = x.iloc[linhas_treino], x.iloc[linhas_valid]
    y_treino , y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]
    ## o modelo de fato usando o randon forrest
    modelo_forest = RandomForestClassifier(n_estimators = 100 , n_jobs =-1, random_state=0)
    modelo_forest.fit(x_treino,y_treino)

    previsaocruzada_forest = modelo.predict(x_valid)
    acuracia_forest = np.mean (y_valid == previsaocruzada_forest)
    resultados3.append(acuracia_forest)
    print("A Acuracia é de : ", acuracia_forest)
    print()
    print()
    
    
    ###### Aqui o teste usando o gradientboosting 
for linhas_treino , linhas_valid in kf.split(x) :
    print("Treino",linhas_treino.shape[0])
    print ("Valid", linhas_valid.shape[0])
    print()
    x_treino , x_valid = x.iloc[linhas_treino], x.iloc[linhas_valid]
    y_treino , y_valid = y.iloc[linhas_treino], y.iloc[linhas_valid]

    modelo_gradient = GradientBoostingClassifier(random_state = 0, n_iter_no_change = 100)
    modelo_gradient.fit(x_treino, y_treino)
    previsaocruzada_gradient = modelo.predict(x_valid)
    acuracia_gradiente = np.mean (y_valid == previsaocruzada_gradient)
    resultados2.append(acuracia_gradiente)
    print("A Acuracia é de : ", acuracia_gradiente)
    print()
    print()
    
    
    
    
    ### Analizando as medias 
resultado_gradient=sum(resultados2) / len(resultados2)
resultado_forrest=sum(resultados3) / len(resultados3)

# analizando 
print('Os valores encontrados nos resultados usando o teste de gradient', resultados2)
print ()
print ('A media desses valores é :',resultado_gradient)
print ()
print ()
print('Os valores encontrados nos resultados usando o teste de forrest', resultados3)
print ()
print ('A media desses valores é :',resultado_forrest)

print ()
print ()
print ()

print('As medias retornaram valores igual, provando que os resultados independente do tipo de modelo')
print ( "não inetrferem tanto no resultado ")

